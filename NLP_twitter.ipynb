{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Natural Language Processing with Disaster Tweets","metadata":{}},{"cell_type":"markdown","source":"To get started with the classification task we need to observe our data, for this we use a DataFrame.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ntrain_csv = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T16:33:48.762568Z","iopub.execute_input":"2024-08-05T16:33:48.762928Z","iopub.status.idle":"2024-08-05T16:33:49.255242Z","shell.execute_reply.started":"2024-08-05T16:33:48.762894Z","shell.execute_reply":"2024-08-05T16:33:49.254038Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"We inspect our DataFrame, recognize our label which we will turn into 'y' later.  \nFor this task initially i have decided to only use our 'text' feature considering it's importance.  \nThe datapoints under text represent the tweets, for this task this holds the most information by far given all our features.  \n\nIt might have value to add the remaining 2 features, but they containt a lot of NaN values.  ","metadata":{}},{"cell_type":"code","source":"train_csv","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.256872Z","iopub.execute_input":"2024-08-05T16:33:49.257244Z","iopub.status.idle":"2024-08-05T16:33:49.277617Z","shell.execute_reply.started":"2024-08-05T16:33:49.257212Z","shell.execute_reply":"2024-08-05T16:33:49.276164Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"         id keyword location  \\\n0         1     NaN      NaN   \n1         4     NaN      NaN   \n2         5     NaN      NaN   \n3         6     NaN      NaN   \n4         7     NaN      NaN   \n...     ...     ...      ...   \n7608  10869     NaN      NaN   \n7609  10870     NaN      NaN   \n7610  10871     NaN      NaN   \n7611  10872     NaN      NaN   \n7612  10873     NaN      NaN   \n\n                                                   text  target  \n0     Our Deeds are the Reason of this #earthquake M...       1  \n1                Forest fire near La Ronge Sask. Canada       1  \n2     All residents asked to 'shelter in place' are ...       1  \n3     13,000 people receive #wildfires evacuation or...       1  \n4     Just got sent this photo from Ruby #Alaska as ...       1  \n...                                                 ...     ...  \n7608  Two giant cranes holding a bridge collapse int...       1  \n7609  @aria_ahrary @TheTawniest The out of control w...       1  \n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n7611  Police investigating after an e-bike collided ...       1  \n7612  The Latest: More Homes Razed by Northern Calif...       1  \n\n[7613 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Lets check datapoint nr. 35  \nHere we see:  \n- keyword\n- location\n- text","metadata":{}},{"cell_type":"code","source":"for tweet in train_csv['keyword'][35:36]: print(tweet)\nfor tweet in train_csv['location'][35:36]: print(tweet)    \nfor tweet in train_csv['text'][35:36]: print(tweet)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.279239Z","iopub.execute_input":"2024-08-05T16:33:49.280197Z","iopub.status.idle":"2024-08-05T16:33:49.287840Z","shell.execute_reply.started":"2024-08-05T16:33:49.280151Z","shell.execute_reply":"2024-08-05T16:33:49.286728Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"ablaze\nLondon, UK\nOn plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N\n","output_type":"stream"}]},{"cell_type":"markdown","source":"X represents our dataset, and y represents our labels.  \nWe create a dataframe that holds both.","metadata":{}},{"cell_type":"code","source":"X_y = train_csv[[\"text\",\"target\"]].copy()\n\nX_y","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.291192Z","iopub.execute_input":"2024-08-05T16:33:49.291609Z","iopub.status.idle":"2024-08-05T16:33:49.311743Z","shell.execute_reply.started":"2024-08-05T16:33:49.291573Z","shell.execute_reply":"2024-08-05T16:33:49.310387Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                   text  target\n0     Our Deeds are the Reason of this #earthquake M...       1\n1                Forest fire near La Ronge Sask. Canada       1\n2     All residents asked to 'shelter in place' are ...       1\n3     13,000 people receive #wildfires evacuation or...       1\n4     Just got sent this photo from Ruby #Alaska as ...       1\n...                                                 ...     ...\n7608  Two giant cranes holding a bridge collapse int...       1\n7609  @aria_ahrary @TheTawniest The out of control w...       1\n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n7611  Police investigating after an e-bike collided ...       1\n7612  The Latest: More Homes Razed by Northern Calif...       1\n\n[7613 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# PreProcessing  \nWe now have to test if our datapoints hold any NaN values.  \nWe assume our labels 'target' dont hold any, in case they do, we'd have to correct this else supervised training is not possible.  \n\nWe test this through a simple loop, shown below.  ","metadata":{}},{"cell_type":"code","source":"for col in X_y:\n    if X_y[col].isnull().any(): print(f\"NaN values are present in {col}\")\n    else: print(f\"No NaN values in {col}\")\n\n# Alternatively we can use list comprehension.\n[col for col in X_y if X_y[col].isnull().any()]","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.313066Z","iopub.execute_input":"2024-08-05T16:33:49.313439Z","iopub.status.idle":"2024-08-05T16:33:49.325657Z","shell.execute_reply.started":"2024-08-05T16:33:49.313407Z","shell.execute_reply":"2024-08-05T16:33:49.324580Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"No NaN values in text\nNo NaN values in target\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"markdown","source":"This is good news, we don't need to worry about imputation.  \nMeaning that the next step is cleaning up our single feature column to make it more effective.  \nNLTK has many tricks to represent our data.    \n\nBut first we will do some manual work.  \n- Remove numbers \n- Remove punctuation\n- Convert to lowercase\n\nLet's take a look at some example tweets first","metadata":{}},{"cell_type":"code","source":"for tweet in X_y['text'].head(): print(tweet)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.327110Z","iopub.execute_input":"2024-08-05T16:33:49.327543Z","iopub.status.idle":"2024-08-05T16:33:49.337581Z","shell.execute_reply.started":"2024-08-05T16:33:49.327504Z","shell.execute_reply":"2024-08-05T16:33:49.336133Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\nForest fire near La Ronge Sask. Canada\nAll residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n13,000 people receive #wildfires evacuation orders in California \nJust got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n","output_type":"stream"}]},{"cell_type":"markdown","source":"our machine considers 'ALLAH' and 'allah' as well as other variations such as 'Allah' to all be seperate words.  \nTo fix this first we convert everything to lowercase. \nSomething as seen below:  ","metadata":{}},{"cell_type":"code","source":"for tweet in X_y['text'].head(): print(tweet.lower())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.338843Z","iopub.execute_input":"2024-08-05T16:33:49.339196Z","iopub.status.idle":"2024-08-05T16:33:49.349600Z","shell.execute_reply.started":"2024-08-05T16:33:49.339166Z","shell.execute_reply":"2024-08-05T16:33:49.348425Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"our deeds are the reason of this #earthquake may allah forgive us all\nforest fire near la ronge sask. canada\nall residents asked to 'shelter in place' are being notified by officers. no other evacuation or shelter in place orders are expected\n13,000 people receive #wildfires evacuation orders in california \njust got sent this photo from ruby #alaska as smoke from #wildfires pours into a school \n","output_type":"stream"}]},{"cell_type":"markdown","source":"To implement this, we do the following:","metadata":{}},{"cell_type":"code","source":"X_y['text'] = X_y['text'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.351049Z","iopub.execute_input":"2024-08-05T16:33:49.351410Z","iopub.status.idle":"2024-08-05T16:33:49.368632Z","shell.execute_reply.started":"2024-08-05T16:33:49.351378Z","shell.execute_reply":"2024-08-05T16:33:49.367337Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"As we can see our DataFrame is succesfully converted.  ","metadata":{}},{"cell_type":"code","source":"X_y","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.370132Z","iopub.execute_input":"2024-08-05T16:33:49.370524Z","iopub.status.idle":"2024-08-05T16:33:49.388021Z","shell.execute_reply.started":"2024-08-05T16:33:49.370490Z","shell.execute_reply":"2024-08-05T16:33:49.386818Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   text  target\n0     our deeds are the reason of this #earthquake m...       1\n1                forest fire near la ronge sask. canada       1\n2     all residents asked to 'shelter in place' are ...       1\n3     13,000 people receive #wildfires evacuation or...       1\n4     just got sent this photo from ruby #alaska as ...       1\n...                                                 ...     ...\n7608  two giant cranes holding a bridge collapse int...       1\n7609  @aria_ahrary @thetawniest the out of control w...       1\n7610  m1.94 [01:04 utc]?5km s of volcano hawaii. htt...       1\n7611  police investigating after an e-bike collided ...       1\n7612  the latest: more homes razed by northern calif...       1\n\n[7613 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>our deeds are the reason of this #earthquake m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>forest fire near la ronge sask. canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>just got sent this photo from ruby #alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>@aria_ahrary @thetawniest the out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>m1.94 [01:04 utc]?5km s of volcano hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>the latest: more homes razed by northern calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Next we'll be using a regex to remove all non-letter characters from 'text' column.","metadata":{}},{"cell_type":"code","source":"X_y['text'] = X_y['text'].str.replace('[^a-zA-Z\\s]', '', regex=True)\n\n\n# X_y['text'] = X_y['text'].str.replace('[^\\w\\s]', '', regex=True)\n# X_y['text'] = X_y['text'].str.replace('\\d+', '', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.389639Z","iopub.execute_input":"2024-08-05T16:33:49.390070Z","iopub.status.idle":"2024-08-05T16:33:49.455632Z","shell.execute_reply.started":"2024-08-05T16:33:49.390030Z","shell.execute_reply":"2024-08-05T16:33:49.454404Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"We can observe our final product below. But there are still ways NLTK can help us work better with feature extraction...","metadata":{}},{"cell_type":"code","source":"for tweet in X_y['text'].head(): print(tweet.lower())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.456989Z","iopub.execute_input":"2024-08-05T16:33:49.457333Z","iopub.status.idle":"2024-08-05T16:33:49.464530Z","shell.execute_reply.started":"2024-08-05T16:33:49.457290Z","shell.execute_reply":"2024-08-05T16:33:49.463397Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"our deeds are the reason of this earthquake may allah forgive us all\nforest fire near la ronge sask canada\nall residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected\n people receive wildfires evacuation orders in california \njust got sent this photo from ruby alaska as smoke from wildfires pours into a school \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# NLTK","metadata":{}},{"cell_type":"markdown","source":"The first thing we apply is filtering stop words, words without much meaningful information such as \"the, with, and...\"  \nDoing this makes our dataset much more efficient which might not be neccessary for small scale projects as these, but is a good practice.","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\nstop = stopwords.words('english')\n\ndef remove_stopwords(text):\n    words = text.split()  \n    filtered_words = [word for word in words if word not in stop]  \n    return ' '.join(filtered_words)  \n\nX_y['text'] = X_y['text'].apply(remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:49.466137Z","iopub.execute_input":"2024-08-05T16:33:49.466704Z","iopub.status.idle":"2024-08-05T16:33:50.611025Z","shell.execute_reply.started":"2024-08-05T16:33:49.466626Z","shell.execute_reply":"2024-08-05T16:33:50.609828Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"As seen below we can still read the sentences and extract the message from it, not much of value is lost.","metadata":{}},{"cell_type":"code","source":"for tweet in X_y['text'].head(): print(tweet.lower())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:50.617034Z","iopub.execute_input":"2024-08-05T16:33:50.617438Z","iopub.status.idle":"2024-08-05T16:33:50.624142Z","shell.execute_reply.started":"2024-08-05T16:33:50.617406Z","shell.execute_reply":"2024-08-05T16:33:50.622726Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"deeds reason earthquake may allah forgive us\nforest fire near la ronge sask canada\nresidents asked shelter place notified officers evacuation shelter place orders expected\npeople receive wildfires evacuation orders california\ngot sent photo ruby alaska smoke wildfires pours school\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now we will do the same but for something called stemming, which might make things harder for us but helps machines.","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nX_y['text'] = X_y['text'].apply(word_tokenize)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:50.625653Z","iopub.execute_input":"2024-08-05T16:33:50.626101Z","iopub.status.idle":"2024-08-05T16:33:52.244873Z","shell.execute_reply.started":"2024-08-05T16:33:50.626059Z","shell.execute_reply":"2024-08-05T16:33:52.243716Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\n\nstemmer = PorterStemmer()\ndef stem_words(words):\n    filtered_words = [stemmer.stem(word) for word in words]\n    return ' '.join(filtered_words)\n\nX_y['text'] = X_y['text'].apply(stem_words)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:52.246258Z","iopub.execute_input":"2024-08-05T16:33:52.246603Z","iopub.status.idle":"2024-08-05T16:33:55.135095Z","shell.execute_reply.started":"2024-08-05T16:33:52.246564Z","shell.execute_reply":"2024-08-05T16:33:55.133910Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for tweet in X_y['text'].head(): print(tweet.lower())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:55.136905Z","iopub.execute_input":"2024-08-05T16:33:55.137276Z","iopub.status.idle":"2024-08-05T16:33:55.143673Z","shell.execute_reply.started":"2024-08-05T16:33:55.137245Z","shell.execute_reply":"2024-08-05T16:33:55.142397Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"deed reason earthquak may allah forgiv us\nforest fire near la rong sask canada\nresid ask shelter place notifi offic evacu shelter place order expect\npeopl receiv wildfir evacu order california\ngot sent photo rubi alaska smoke wildfir pour school\n","output_type":"stream"}]},{"cell_type":"markdown","source":"stemming takes words to a more basic form, even ones that aren't correct in reality. But this does not matter, what matters is that the machine can recognize relations in words.  \nWith stemming the machine can link together 'forgiving' and 'forgiveness', but without stemming has a harder time.","metadata":{}},{"cell_type":"markdown","source":"# Vectorizing\n\nWith our data being preprocessed the next step is converting it to matrix form so our machine can be trained in ways ML models prefer.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(max_features=5000)\nX = tfidf.fit_transform(X_y['text'])\ny = X_y['target']","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:55.145617Z","iopub.execute_input":"2024-08-05T16:33:55.146140Z","iopub.status.idle":"2024-08-05T16:33:55.375645Z","shell.execute_reply.started":"2024-08-05T16:33:55.146098Z","shell.execute_reply":"2024-08-05T16:33:55.374403Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"a few things to note here:  \n- X is our dataset excluding our label, which in this case is just our 'text' feature.  \n- y is our label, this contains the true value of what we're trying to predict.\n- max_features is a hyperparameter.","metadata":{}},{"cell_type":"markdown","source":"# Machine Learning Models\n\nFirst thing to do is splitting our data to check our models performance during training.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:55.377036Z","iopub.execute_input":"2024-08-05T16:33:55.377437Z","iopub.status.idle":"2024-08-05T16:33:55.386982Z","shell.execute_reply.started":"2024-08-05T16:33:55.377402Z","shell.execute_reply":"2024-08-05T16:33:55.385683Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"**Random Forest Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\nmodel_rf = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel_rf.fit(X_train, y_train)\ny_pred_rf = model_rf.predict(X_test)\nprint(\"Random Forest: \")\nprint(classification_report(y_test, y_pred_rf))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:33:55.388543Z","iopub.execute_input":"2024-08-05T16:33:55.389034Z","iopub.status.idle":"2024-08-05T16:34:04.995716Z","shell.execute_reply.started":"2024-08-05T16:33:55.389001Z","shell.execute_reply":"2024-08-05T16:34:04.994593Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Random Forest: \n              precision    recall  f1-score   support\n\n           0       0.79      0.85      0.82      1318\n           1       0.77      0.69      0.73       966\n\n    accuracy                           0.78      2284\n   macro avg       0.78      0.77      0.77      2284\nweighted avg       0.78      0.78      0.78      2284\n\nAccuracy: 0.7832749562171629\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Naive Bayes**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nmodel_nb = MultinomialNB()\nmodel_nb.fit(X_train, y_train)\ny_pred_nb = model_nb.predict(X_test)\nprint(\"Naive Bayes: \")\nprint(classification_report(y_test, y_pred_nb))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:04.997164Z","iopub.execute_input":"2024-08-05T16:34:04.997529Z","iopub.status.idle":"2024-08-05T16:34:05.024529Z","shell.execute_reply.started":"2024-08-05T16:34:04.997498Z","shell.execute_reply":"2024-08-05T16:34:05.023377Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Naive Bayes: \n              precision    recall  f1-score   support\n\n           0       0.80      0.90      0.84      1318\n           1       0.83      0.69      0.75       966\n\n    accuracy                           0.81      2284\n   macro avg       0.81      0.79      0.80      2284\nweighted avg       0.81      0.81      0.80      2284\n\nAccuracy: 0.808231173380035\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Logistic Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmodel_lr = LogisticRegression(max_iter=1000, random_state=42)\nmodel_lr.fit(X_train, y_train)\ny_pred_lr = model_lr.predict(X_test)\nprint(\"Logistic Regression: \")\nprint(classification_report(y_test, y_pred_lr))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:05.025829Z","iopub.execute_input":"2024-08-05T16:34:05.026180Z","iopub.status.idle":"2024-08-05T16:34:05.119970Z","shell.execute_reply.started":"2024-08-05T16:34:05.026150Z","shell.execute_reply":"2024-08-05T16:34:05.118763Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Logistic Regression: \n              precision    recall  f1-score   support\n\n           0       0.79      0.90      0.84      1318\n           1       0.84      0.68      0.75       966\n\n    accuracy                           0.81      2284\n   macro avg       0.82      0.79      0.80      2284\nweighted avg       0.81      0.81      0.80      2284\n\nAccuracy: 0.8086690017513135\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Support Vector Machine**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nmodel_svm = SVC(kernel='linear', random_state=42)\nmodel_svm.fit(X_train, y_train)\n\n# Make predictions\ny_pred_svm = model_svm.predict(X_test)\n\n# Evaluate model\nprint(classification_report(y_test, y_pred_svm))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:05.121654Z","iopub.execute_input":"2024-08-05T16:34:05.122593Z","iopub.status.idle":"2024-08-05T16:34:07.846859Z","shell.execute_reply.started":"2024-08-05T16:34:05.122538Z","shell.execute_reply":"2024-08-05T16:34:07.845663Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84      1318\n           1       0.81      0.69      0.75       966\n\n    accuracy                           0.80      2284\n   macro avg       0.80      0.79      0.79      2284\nweighted avg       0.80      0.80      0.80      2284\n\nAccuracy: 0.8003502626970228\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Multi Layer Perceptron**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import classification_report\n\n# Define a more complex MLP model\nmodel_mlp = Sequential([\n    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dense(1, activation='sigmoid') \n])\n\n# Compile the model\nmodel_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True)\n\n# Train the model\nmodel_mlp.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1, callbacks=[early_stopping, model_checkpoint])\n\n# Evaluate the model\nloss, accuracy = model_mlp.evaluate(X_test, y_test)\nprint(f'Test Accuracy: {accuracy:.4f}')\n\n# Predict classes\ny_pred_mlp = model_mlp.predict(X_test)\ny_pred_classes = (y_pred_mlp > 0.5).astype(int)\n\n# Generate classification report\nreport = classification_report(y_test, y_pred_classes, target_names=['Non-Disaster', 'Disaster'])\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:07.848473Z","iopub.execute_input":"2024-08-05T16:34:07.848921Z","iopub.status.idle":"2024-08-05T16:34:20.012498Z","shell.execute_reply.started":"2024-08-05T16:34:07.848881Z","shell.execute_reply":"2024-08-05T16:34:20.011358Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2024-08-05 16:34:08.289808: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-05 16:34:08.289878: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-05 16:34:08.291648: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5672 - loss: 0.6739 - val_accuracy: 0.7655 - val_loss: 0.4970\nEpoch 2/30\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8236 - loss: 0.4235 - val_accuracy: 0.7992 - val_loss: 0.4566\nEpoch 3/30\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8969 - loss: 0.2735 - val_accuracy: 0.7992 - val_loss: 0.4859\nEpoch 4/30\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9306 - loss: 0.1961 - val_accuracy: 0.7842 - val_loss: 0.5194\nEpoch 5/30\n\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.1643 - val_accuracy: 0.7824 - val_loss: 0.6230\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7987 - loss: 0.4699\nTest Accuracy: 0.8052\n\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n              precision    recall  f1-score   support\n\nNon-Disaster       0.82      0.86      0.84      1318\n    Disaster       0.79      0.74      0.76       966\n\n    accuracy                           0.81      2284\n   macro avg       0.80      0.80      0.80      2284\nweighted avg       0.80      0.81      0.80      2284\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Voting Classifier**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nvoting_classifier = VotingClassifier(estimators=[('rf', model_rf), ('nb', model_nb), ('lr', model_lr), ('svm', model_svm)], voting='hard')\nvoting_classifier.fit(X_train, y_train)\n\ny_pred_vc = voting_classifier.predict(X_test)\nprint(\"Voting Classifier: \")\nprint(classification_report(y_test, y_pred_vc))\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred_vc))","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:20.014224Z","iopub.execute_input":"2024-08-05T16:34:20.015069Z","iopub.status.idle":"2024-08-05T16:34:32.653054Z","shell.execute_reply.started":"2024-08-05T16:34:20.015025Z","shell.execute_reply":"2024-08-05T16:34:32.651890Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Voting Classifier: \n              precision    recall  f1-score   support\n\n           0       0.79      0.92      0.85      1318\n           1       0.86      0.66      0.75       966\n\n    accuracy                           0.81      2284\n   macro avg       0.82      0.79      0.80      2284\nweighted avg       0.82      0.81      0.81      2284\n\nAccuracy: 0.8108581436077058\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Neural network MLP\nadd other features to words","metadata":{}},{"cell_type":"markdown","source":"# Test Data Conversion","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\ntest_df['text'] = test_df['text'].str.lower()  # Lowercase text\ntest_df['text'] = test_df['text'].str.replace('[^\\w\\s]', '', regex=True)  # Remove punctuation marks\ntest_df['text'] = test_df['text'].str.replace('\\d+', '', regex=True)  # Remove numbers\n\n# Remove stop words\ntest_df['text'] = test_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n\n# Tokenization\ntest_df['text'] = test_df['text'].apply(word_tokenize)\n\n# Stemming\ntest_df['text'] = test_df['text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x]))\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:32.655248Z","iopub.execute_input":"2024-08-05T16:34:32.655727Z","iopub.status.idle":"2024-08-05T16:34:34.799118Z","shell.execute_reply.started":"2024-08-05T16:34:32.655685Z","shell.execute_reply":"2024-08-05T16:34:34.797730Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                           happen terribl car crash\n1   2     NaN      NaN      heard earthquak differ citi stay safe everyon\n2   3     NaN      NaN  forest fire spot pond gees flee across street ...\n3   9     NaN      NaN                     apocalyps light spokan wildfir\n4  11     NaN      NaN                 typhoon soudelor kill china taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>happen terribl car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>heard earthquak differ citi stay safe everyon</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>forest fire spot pond gees flee across street ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>apocalyps light spokan wildfir</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>typhoon soudelor kill china taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Voting Classifier","metadata":{}},{"cell_type":"code","source":"test = tfidf.transform(test_df['text'])\ntest_df['target'] = voting_classifier.predict(test)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:34.800571Z","iopub.execute_input":"2024-08-05T16:34:34.801034Z","iopub.status.idle":"2024-08-05T16:34:36.147039Z","shell.execute_reply.started":"2024-08-05T16:34:34.800996Z","shell.execute_reply":"2024-08-05T16:34:36.145877Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"results = test_df[['id', 'target']]\nresults.to_csv('nlp_disaster_submission_fraud.csv', index=False)\n\nresults","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:36.148508Z","iopub.execute_input":"2024-08-05T16:34:36.148954Z","iopub.status.idle":"2024-08-05T16:34:36.170265Z","shell.execute_reply.started":"2024-08-05T16:34:36.148906Z","shell.execute_reply":"2024-08-05T16:34:36.169213Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"         id  target\n0         0       1\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       0\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# MLP Classifier","metadata":{}},{"cell_type":"code","source":"import numpy as np \n\ntest_mlp_pred = np.squeeze(model_mlp.predict(test))\ntest_df['target'] = (test_mlp_pred > 0.5).astype(int)\n\nresults = test_df[['id', 'target']]\nresults.to_csv('mlp_disaster_submission.csv', index=False)\n\nresults","metadata":{"execution":{"iopub.status.busy":"2024-08-05T16:34:36.171870Z","iopub.execute_input":"2024-08-05T16:34:36.172217Z","iopub.status.idle":"2024-08-05T16:34:36.653071Z","shell.execute_reply.started":"2024-08-05T16:34:36.172186Z","shell.execute_reply":"2024-08-05T16:34:36.651812Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"         id  target\n0         0       1\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       1\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]}]}